<!doctype html><html lang=en-us>
<head>
<meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<title>Coordinator HA in Trino with reverse nginx proxy - Home</title><meta name=description content="All config files and a full docker-compose.yaml file for recreating what is covered in this article can be found in this github repository.
 This article demonstrates how coordinator HA can be achieved with an nginx reverse proxy using docker. Note that this is not a production setup. The intent of this article is to show how coordinator HA can be achieved. I&rsquo;ve used similar concepts with real-world deployments but I&rsquo;ve used a hardware load balancer instead of nginx for this in production.">
<meta name=author content>
<link rel="preload stylesheet" as=style href=https://posulliv.github.io/app.min.css>
<link rel="preload stylesheet" as=style href=https://posulliv.github.io/an-old-hope.min.css>
<script defer src=https://posulliv.github.io/highlight.min.js onload=hljs.initHighlightingOnLoad()></script>
<link rel=preload as=image href=https://posulliv.github.io/theme.png>
<link rel=preload as=image href=https://posulliv.github.io/twitter.svg>
<link rel=preload as=image href=https://posulliv.github.io/github.svg>
<link rel=icon href=https://posulliv.github.io/favicon.ico>
<link rel=apple-touch-icon href=https://posulliv.github.io/apple-touch-icon.png>
<meta name=generator content="Hugo 0.93.1">
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","G-RB870JF93J","auto"),ga("send","pageview"))</script>
<script async src=https://www.google-analytics.com/analytics.js></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-RB870JF93J"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-RB870JF93J",{anonymize_ip:!1})}</script>
<meta property="og:title" content="Coordinator HA in Trino with reverse nginx proxy">
<meta property="og:description" content="All config files and a full docker-compose.yaml file for recreating what is covered in this article can be found in this github repository.
 This article demonstrates how coordinator HA can be achieved with an nginx reverse proxy using docker. Note that this is not a production setup. The intent of this article is to show how coordinator HA can be achieved. I&rsquo;ve used similar concepts with real-world deployments but I&rsquo;ve used a hardware load balancer instead of nginx for this in production.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://posulliv.github.io/posts/coordinator-ha/"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2022-01-10T11:18:51-05:00">
<meta property="article:modified_time" content="2022-01-10T11:18:51-05:00">
<meta itemprop=name content="Coordinator HA in Trino with reverse nginx proxy">
<meta itemprop=description content="All config files and a full docker-compose.yaml file for recreating what is covered in this article can be found in this github repository.
 This article demonstrates how coordinator HA can be achieved with an nginx reverse proxy using docker. Note that this is not a production setup. The intent of this article is to show how coordinator HA can be achieved. I&rsquo;ve used similar concepts with real-world deployments but I&rsquo;ve used a hardware load balancer instead of nginx for this in production."><meta itemprop=datePublished content="2022-01-10T11:18:51-05:00">
<meta itemprop=dateModified content="2022-01-10T11:18:51-05:00">
<meta itemprop=wordCount content="545">
<meta itemprop=keywords content>
<meta name=twitter:card content="summary">
<meta name=twitter:title content="Coordinator HA in Trino with reverse nginx proxy">
<meta name=twitter:description content="All config files and a full docker-compose.yaml file for recreating what is covered in this article can be found in this github repository.
 This article demonstrates how coordinator HA can be achieved with an nginx reverse proxy using docker. Note that this is not a production setup. The intent of this article is to show how coordinator HA can be achieved. I&rsquo;ve used similar concepts with real-world deployments but I&rsquo;ve used a hardware load balancer instead of nginx for this in production.">
</head><body class=not-ready data-menu=false>
<head>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-RB870JF93J"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-RB870JF93J",{anonymize_ip:!1})}</script>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","G-RB870JF93J","auto"),ga("send","pageview"))</script>
<script async src=https://www.google-analytics.com/analytics.js></script>
</head><header class=header>
<p class=logo>
<a class=site-name href=https://posulliv.github.io/>Home</a><a class=btn-dark></a>
</p><script>let bodyClx=document.body.classList,btnDark=document.querySelector(".btn-dark"),sysDark=window.matchMedia("(prefers-color-scheme: dark)"),darkVal=localStorage.getItem("dark"),setDark=e=>{bodyClx[e?"add":"remove"]("dark"),localStorage.setItem("dark",e?"yes":"no")};setDark(darkVal?darkVal==="yes":sysDark.matches),requestAnimationFrame(()=>bodyClx.remove("not-ready")),btnDark.addEventListener("click",()=>setDark(!bodyClx.contains("dark"))),sysDark.addEventListener("change",e=>setDark(e.matches))</script>
<nav class=social>
<a class=twitter style=--url:url(./twitter.svg) href=https://twitter.com/posulliv target=_blank></a>
<a class=github style=--url:url(./github.svg) href=https://github.com/posulliv target=_blank></a>
</nav></header><main class=main>
<article class=post-single>
<header class=post-title>
<p>
<time>Jan 10, 2022</time>
</p><h1>Coordinator HA in Trino with reverse nginx proxy</h1></header><section class=post-content><blockquote>
<p>All config files and a full <code>docker-compose.yaml</code> file for recreating
what is covered in this article can be found in
<a href=https://github.com/posulliv/trino-coordinator-ha-demo>this github repository</a>.</p></blockquote><p>This article demonstrates how coordinator HA can be achieved with an nginx
reverse proxy using docker. Note that this is not a production setup. The
intent of this article is to show how coordinator HA can be achieved. I&rsquo;ve
used similar concepts with real-world deployments but I&rsquo;ve used a hardware
load balancer instead of nginx for this in production.</p><p>With that said, lets continue! We will set up 3 Trino containers:</p><ul>
<li>coordinator A listening on port 8080- named <code>trino_a</code></li><li>coordinator B listening on port 8081 - named <code>trino_b</code></li><li>worker - named <code>trino_worker</code></li></ul><p>We will also start an Nginx container named Nginx. The nginx configuration for
setting up the reverse proxy will look like:</p><pre tabindex=0><code>upstream trino {
   server trino_a:8080 fail_timeout=3s max_fails=1;
   server trino_b:8081 backup;
}

server {
    listen       80;
    server_name  localhost;
    location / {
        proxy_pass   http://trino;
        proxy_redirect  http://trino/ /;
        proxy_connect_timeout 3;

        proxy_set_header          Host            $host;
        proxy_set_header          X-Real-IP       $remote_addr;
        proxy_set_header          X-Forwarded-For $proxy_add_x_forwarded_for;
    }
}
</code></pre><p>The <code>upstream</code> section of the Nginx config is what configures the servers behind
the reverse proxy. The backup directive indicates no traffic will go to <code>trino_b</code>
until <code>trino_a</code> has a timeout failure of 3 seconds.</p><p>In the <code>server</code> section, the proxy is configured to listen on port 80. This is
the port our end users will be connecting to Trino with. The <code>location</code> section
then configures the proxy to pass all traffic to http://trino</p><p>The <code>proxy_set_header</code> options are required in order to ensure that POST requests
are forwarded correctly by the proxy to Trino.</p><p>The discovery URI for the coordinators needs to point at localhost to ensure they
never communicate with a different coordinator.</p><p>Coordinator A <code>config.properties</code> looks like:</p><pre tabindex=0><code>coordinator=true
node-scheduler.include-coordinator=true
http-server.http.port=8080
query.max-memory=1.4GB
query.max-memory-per-node=1.4GB
query.max-total-memory-per-node=1.4GB
discovery.uri=http://localhost:8080
</code></pre><p>Coordinator B <code>config.properties</code> looks like:</p><pre tabindex=0><code>coordinator=true
node-scheduler.include-coordinator=true
http-server.http.port=8081
query.max-memory=1.4GB
query.max-memory-per-node=1.4GB
query.max-total-memory-per-node=1.4GB
discovery.uri=http://localhost:8081
</code></pre><p>Now any worker must be configured to use the URL of the reverse proxy for
<code>discovery.uri</code>. This means that if one of the coordinator’s go down, the
worker will start making announcements to the backup coordinator since all
its requests go through the reverse proxy. The worker’s <code>config.properties</code>
looks like:</p><pre tabindex=0><code>coordinator=false
query.max-memory=1.4GB
query.max-memory-per-node=1.4GB
query.max-total-memory-per-node=1.4GB
discovery.uri=http://nginx:80
</code></pre><p>Assuming we have started up all our containers, an end user would connect
using the CLI like so:</p><pre tabindex=0><code>trino --server http://localhost/ --user padraig --debug
</code></pre><p>Verify we have a coordinator and 1 worker in this cluster:</p><pre tabindex=0><code>trino&gt; select * from system.runtime.nodes;
   node_id    |        http_uri        | node_version | coordinator | state
--------------+------------------------+--------------+-------------+--------
 f8150fcfb049 | http://172.30.0.2:8080 | 364          | true        | active
 4c10ceb56ca3 | http://172.30.0.3:8080 | 364          | false       | active
(2 rows)

Query 20211202_151305_00000_3cki7, FINISHED, 2 nodes
http://localhost/ui/query.html?20211202_151305_00000_3cki7

trino&gt;
</code></pre><p>Now, kill the active coordinator container trino_a and verify we can still
connect and still have 1 worker in the cluster:</p><pre tabindex=0><code>trino&gt; select * from system.runtime.nodes;
   node_id    |        http_uri        | node_version | coordinator | state
--------------+------------------------+--------------+-------------+--------
 4c10ceb56ca3 | http://172.30.0.3:8080 | 364          | false       | active
 8a42a7e8d105 | http://172.30.0.4:8081 | 364          | true        | active
(2 rows)

Query 20211202_151406_00001_ewe87, FINISHED, 2 nodes
http://localhost/ui/query.html?20211202_151406_00001_ewe87

trino&gt;
</code></pre><p>Notice the <code>http_uri</code> of the coordinator is different (now port 8081) which
indicates we are using the <code>trino_b</code> coordinator.</p><p>Again, this is not a production setup but demonstrates how coordinator HA can
be achieved in a Trino cluster.</p></section><nav class=post-nav>
<a class=prev href=https://posulliv.github.io/posts/writes-from-trino/><span>←</span><span>Notes on writing with the Hive connector in Trino</span></a>
</nav></article></main><footer class=footer>
<p>&copy; 2022 <a href=https://posulliv.github.io/>Home</a></p><p>Powered by <a href=https://gohugo.io/ rel=noopener target=_blank>Hugo️️</a>️</p><p>
<a href=https://github.com/nanxiaobei/hugo-paper rel=noopener target=_blank>Paper 5.1</a>
</p></footer></body></html>